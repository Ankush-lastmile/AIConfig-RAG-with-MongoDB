{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install python dependencies. Run Once.\n",
    "# MongoDB reccomends `python -m pip install \"pymongo[srv]\"==3.11` or whatever version of python you are using\n",
    "%pip install pymongo\n",
    "%pip install pypdf\n",
    "%pip install langchain\n",
    "%pip install langchain_community\n",
    "%pip install langchain_openai\n",
    "%pip install python-aiconfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup your MongoDB Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "\n",
    "# Setup up MongoDB Atlas connection\n",
    "# You can find this connection URI by going to your cluster and clicking connect > Drivers\n",
    "# Connection String looks something like this: \"mongodb+srv://ankush:ankush@cluster0.zqgx7e6.mongodb.net/?retryWrites=true&w=majority\"\n",
    "MONGODB_ATLAS_CLUSTER_URI = \"\"\n",
    "\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(MONGODB_ATLAS_CLUSTER_URI)\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configure Database Details\n",
    "The database will contain vectorized embeddings of your original document (e.g. PDF or webpage). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup DB details.\n",
    "## Create a new Database\n",
    "DB_NAME = \"MY_DB\"\n",
    "db = client[DB_NAME]\n",
    "\n",
    "## Create a new collection\n",
    "COLLECTION_NAME = \"UNIVERSITY_POLICIES\"\n",
    "MONGODB_COLLECTION = db[COLLECTION_NAME]\n",
    "\n",
    "## Index Name. Manually create this in the MongoDB web ui, add documents below, then create the search index in the same name\n",
    "ATLAS_VECTOR_SEARCH_INDEX_NAME = \"vector_index\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Store the embeddings of your document/webpage into the database\n",
    "LangChain helps us split the document/webpage into chunks of text. &nbsp;\n",
    "\n",
    "OpenAI Embedding model is used to create embedding vectors from these chunks of text. We then store these embedding vectors into the database. &nbsp;\n",
    "\n",
    "TODO: Replace with your PDF or webpage URL below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load the PDF, create embeddings, persist in MongoDB Atlas.\n",
    "# Run this cell only one time.\n",
    "pdf_uri = \"https://comm.unc.edu/wp-content/uploads/sites/388/2018/12/UNC-Department-of-Communication-Policy-Manual-Draft-11-10-15-ph-pp.pdf\"\n",
    "loader = PyPDFLoader(pdf_uri)\n",
    "data = loader.load()\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "from langchain_community.vectorstores import MongoDBAtlasVectorSearch\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# insert the documents in MongoDB Atlas with their embedding\n",
    "vector_search = MongoDBAtlasVectorSearch.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=OpenAIEmbeddings(disallowed_special=()),\n",
    "    collection=MONGODB_COLLECTION,\n",
    "    index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define helper method to retrieve the right context (set of vectors) given a user prompt\n",
    "This helper method works help us to retrieve the relevant vectors from the database given a user prompt. In this case, we use cosine-similarity to find the most relevant vectors to the user prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import MongoDBAtlasVectorSearch\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "vector_search = MongoDBAtlasVectorSearch.from_connection_string(\n",
    "    MONGODB_ATLAS_CLUSTER_URI,\n",
    "    DB_NAME + \".\" + COLLECTION_NAME,\n",
    "    OpenAIEmbeddings(disallowed_special=()),\n",
    "    index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",
    ")\n",
    "# Define helper method for Rag with AIConfig\n",
    "def get_knn_context_from_query(query: str, k: int = 1) -> str:\n",
    "    results: list[Document] = vector_search.similarity_search(\n",
    "        query=query, k=k\n",
    "    )\n",
    "    results_as_strings = [doc.page_content for doc in results]\n",
    "    resulting_documents_as_a_string = \"\\n\".join(results_as_strings)\n",
    "\n",
    "    return resulting_documents_as_a_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run prompts on the context retrieved from the database\n",
    "We will the AIConfig JSON template to run prompts over the context retrieved from the database.\n",
    "\n",
    "TODO: Replace the variables: user_question, style_guide, etc. with values/data relevant to your use case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pydantic/_internal/_fields.py:128: UserWarning: Field \"model_parsers\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ExecuteResult(output_type='execute_result', execution_count=0, data='The department central phone line should be covered by the Administrative Support Associate during regular office hours. If the Administrative Support Associate is absent, the Undergraduate Student Services Specialist will cover the phone line. This is stated in Policy Number 107/1 of the UNC Department of Communication.', mime_type=None, metadata={'id': 'chatcmpl-8kNLXBETeay2mHmo8rClJWj0t8J4o', 'created': 1706063523, 'model': 'gpt-3.5-turbo-0613', 'object': 'chat.completion.chunk', 'raw_response': {'content': 'The department central phone line should be covered by the Administrative Support Associate during regular office hours. If the Administrative Support Associate is absent, the Undergraduate Student Services Specialist will cover the phone line. This is stated in Policy Number 107/1 of the UNC Department of Communication.', 'role': 'assistant'}, 'role': 'assistant'})]\n"
     ]
    }
   ],
   "source": [
    "# Use AIConfig to run prompts on the context retrieved from the KNN search\n",
    "\n",
    "from aiconfig import AIConfigRuntime\n",
    "\n",
    "prompt_techniques = AIConfigRuntime.load(\"rag.aiconfig.json\")\n",
    "\n",
    "# TODO: Replace these variables with your own data/values\n",
    "user_question = \"Who should cover the department central phone line?\"\n",
    "style_guide = \"keep sentence structure simple \\n- choose precise words \\n- be direct \\n- answer in 1-2 sentences\\n- provide supporting text to be thorough in answering the question with references and quotes\\n\\n\"\n",
    "role = \"You are a helpful assistant in responding to inquiries from school faculty.\"\n",
    "few_shot_examples = \"\"\n",
    "\n",
    "context = get_knn_context_from_query(user_question)\n",
    "params = {\n",
    "    \"user_question\": user_question,\n",
    "    \"style_guide\": style_guide,\n",
    "    \"role\": role,\n",
    "    \"few_shot_examples\": few_shot_examples,\n",
    "    \"context\": context,\n",
    "}\n",
    "response = await prompt_techniques.run(\"question-answer\", params)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ExecuteResult(output_type='execute_result', execution_count=0, data=\"Yes, the statement is correct. According to Policy Number 107/1 of the UNC Department of Communication, the department central phone line should be covered by the Administrative Support Associate during regular office hours. In case of the Administrative Support Associate's absence, the phone line will be deferred to the Undergraduate Student Services Specialist. This information can be found in the policy document on Phone Coverage, prepared by Penny Harris and approved by Patricia Parker on November 16, 2015.\", mime_type=None, metadata={'id': 'chatcmpl-8kNLajygz1aualYZ8utoLgkboq1jb', 'created': 1706063526, 'model': 'gpt-3.5-turbo-0613', 'object': 'chat.completion.chunk', 'raw_response': {'content': \"Yes, the statement is correct. According to Policy Number 107/1 of the UNC Department of Communication, the department central phone line should be covered by the Administrative Support Associate during regular office hours. In case of the Administrative Support Associate's absence, the phone line will be deferred to the Undergraduate Student Services Specialist. This information can be found in the policy document on Phone Coverage, prepared by Penny Harris and approved by Patricia Parker on November 16, 2015.\", 'role': 'assistant'}, 'role': 'assistant'})]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = await prompt_techniques.run(\"verification\", params)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_techniques.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
